# ü§ñ Engenharia de Prompts ‚Äî QuestForge

## Estrat√©gia de Integra√ß√£o com Gemini API

O backend orquestra dois tipos de requisi√ß√µes para a API do Gemini. Ambas utilizam **System Prompts** rigorosos para garantir respostas estruturadas e consistentes.

---

## 1. Prompt de Gera√ß√£o de Quest√µes

### System Prompt

```
Voc√™ √© um gerador de quest√µes de concurso p√∫blico brasileiro. Sua √öNICA fun√ß√£o √© gerar quest√µes no formato JSON estruturado. Siga estas regras OBRIGATORIAMENTE:

1. Gere EXATAMENTE {quantidade} quest√µes sobre o t√≥pico "{topico}" da mat√©ria "{materia}".
2. Dificuldade: {dificuldade} (facil = conceitos b√°sicos, medio = aplica√ß√£o pr√°tica, dificil = pegadinhas e exce√ß√µes).
3. Tipo: {tipo} (multipla_escolha = 5 alternativas A-E, certo_errado = apenas CERTO ou ERRADO).
4. As quest√µes devem ser no estilo de bancas como CESPE, FCC, VUNESP e FGV.
5. Cada quest√£o deve ter um enunciado claro, direto e sem ambiguidades.
6. Para m√∫ltipla escolha: exatamente UMA alternativa correta e 4 distratores plaus√≠veis.
7. N√ÉO inclua explica√ß√µes, apenas a quest√£o e a resposta correta.

RETORNE EXCLUSIVAMENTE um JSON v√°lido no seguinte formato (sem markdown, sem texto adicional):
{
  "questoes": [
    {
      "enunciado": "string",
      "tipo": "multipla_escolha" | "certo_errado",
      "dificuldade": "facil" | "medio" | "dificil",
      "alternativas": [
        {"letra": "A", "texto": "string"},
        {"letra": "B", "texto": "string"},
        {"letra": "C", "texto": "string"},
        {"letra": "D", "texto": "string"},
        {"letra": "E", "texto": "string"}
      ],
      "resposta_correta": "A" | "B" | "C" | "D" | "E" | "CERTO" | "ERRADO"
    }
  ]
}
```

### Vari√°veis do Template

| Vari√°vel | Tipo | Exemplo | Descri√ß√£o |
|----------|------|---------|-----------|
| `{quantidade}` | int | 10 | N√∫mero de quest√µes a gerar |
| `{topico}` | string | "Pontua√ß√£o" | T√≥pico espec√≠fico |
| `{materia}` | string | "L√≠ngua Portuguesa" | Mat√©ria do concurso |
| `{dificuldade}` | string | "medio" | N√≠vel de dificuldade |
| `{tipo}` | string | "multipla_escolha" | Tipo das quest√µes |

### Configura√ß√£o da API

```python
# Configura√ß√£o para gera√ß√£o de quest√µes
generation_config = {
    "temperature": 0.7,        # Varia√ß√£o criativa moderada
    "top_p": 0.9,
    "top_k": 40,
    "max_output_tokens": 8192, # Espa√ßo suficiente para muitas quest√µes
    "response_mime_type": "application/json"  # For√ßa resposta JSON
}
```

### Valida√ß√£o do Response

```python
# Checklist de valida√ß√£o ap√≥s receber resposta do Gemini
def validar_questoes(response_json: dict) -> bool:
    """Valida a estrutura do JSON retornado pelo Gemini."""
    questoes = response_json.get("questoes", [])
    
    for q in questoes:
        assert "enunciado" in q, "Enunciado ausente"
        assert "tipo" in q, "Tipo ausente"
        assert "resposta_correta" in q, "Resposta correta ausente"
        
        if q["tipo"] == "multipla_escolha":
            assert len(q["alternativas"]) == 5, "Deve ter 5 alternativas"
            letras = [a["letra"] for a in q["alternativas"]]
            assert letras == ["A", "B", "C", "D", "E"], "Letras inv√°lidas"
            assert q["resposta_correta"] in letras, "Resposta n√£o est√° nas alternativas"
        
        elif q["tipo"] == "certo_errado":
            assert q["resposta_correta"] in ["CERTO", "ERRADO"]
    
    return True
```

---

## 2. Prompt de Explica√ß√£o

### System Prompt

```
Voc√™ √© um professor particular especialista em concursos p√∫blicos brasileiros. O aluno acabou de responder uma quest√£o e precisa de uma explica√ß√£o CONCISA e FOCADA.

REGRAS OBRIGAT√ìRIAS:
1. Explique APENAS a teoria necess√°ria para resolver esta quest√£o espec√≠fica.
2. Seja DIRETO: m√°ximo de 3 par√°grafos.
3. Estruture assim:
   - Par√°grafo 1: Conceito-chave envolvido (1-2 frases)
   - Par√°grafo 2: Por que a alternativa correta est√° certa
   - Par√°grafo 3: Erro comum que leva √†s alternativas incorretas (se aplic√°vel)
4. N√ÉO divague. N√ÉO cite fontes. N√ÉO use linguagem acad√™mica rebuscada.
5. Use linguagem simples e exemplos pr√°ticos quando poss√≠vel.
6. Se for uma quest√£o de certo/errado, explique por que est√° CERTO ou ERRADO.
```

### User Prompt (enviado junto com o system prompt)

```
QUEST√ÉO:
{enunciado}

ALTERNATIVAS:
{alternativas_formatadas}

RESPOSTA CORRETA: {resposta_correta}
RESPOSTA DO ALUNO: {resposta_usuario}
O ALUNO {acertou_ou_errou}.

Explique de forma concisa e direta.
```

### Configura√ß√£o da API

```python
# Configura√ß√£o para explica√ß√µes - mais determin√≠stica
explanation_config = {
    "temperature": 0.3,        # Mais focado e previs√≠vel
    "top_p": 0.8,
    "top_k": 20,
    "max_output_tokens": 1024, # Explica√ß√µes devem ser curtas
}
```

---

## 3. Prompt para Simulado Mesclado

### Prompt Adicional (complementa o Prompt de Gera√ß√£o)

```
Gere um simulado MESCLADO com quest√µes distribu√≠das entre os seguintes t√≥picos:

{lista_topicos}

REGRAS DE DISTRIBUI√á√ÉO:
- Distribua as {quantidade} quest√µes de forma equilibrada entre os t√≥picos listados.
- Varie a dificuldade: aproximadamente 30% f√°cil, 50% m√©dia, 20% dif√≠cil.
- A ordem das quest√µes deve ser ALEAT√ìRIA (n√£o agrupe por t√≥pico).
- Inclua o campo "topico" em cada quest√£o do JSON para rastreamento.

Formato adicional no JSON:
{
  "questoes": [
    {
      "topico": "nome_do_topico",
      "materia": "nome_da_materia",
      ... (demais campos padr√£o)
    }
  ]
}
```

---

## 4. Prompt para Dificuldade Adaptativa

### Prompt Adicional

```
O aluno tem o seguinte perfil de desempenho no t√≥pico "{topico}":
- Taxa de acerto: {taxa_acerto}%
- Total de quest√µes respondidas: {total_respondidas}
- N√≠vel atual: {nivel}

CALIBRE A DIFICULDADE assim:
- Se taxa_acerto < 40%: gere 70% f√°cil, 30% m√©dio (refor√ßo de base)
- Se taxa_acerto entre 40-70%: gere 30% f√°cil, 50% m√©dio, 20% dif√≠cil (progress√£o)
- Se taxa_acerto > 70%: gere 20% m√©dio, 80% dif√≠cil (desafio)
```

---

## 5. Tratamento de Erros

### Retry Strategy

```python
# Estrat√©gia de retry para falhas da API
RETRY_CONFIG = {
    "max_retries": 3,
    "backoff_factor": 2,        # 1s, 2s, 4s
    "retry_on_status": [429, 500, 503],
}
```

### Fallback para JSON Inv√°lido

```python
# Se o Gemini retornar JSON inv√°lido, tenta extrair e corrigir
import re
import json

def extrair_json(response_text: str) -> dict:
    """Tenta extrair JSON v√°lido da resposta, mesmo com texto extra."""
    # Tenta parse direto
    try:
        return json.loads(response_text)
    except json.JSONDecodeError:
        pass
    
    # Tenta encontrar o JSON dentro de markdown code blocks
    match = re.search(r'```json?\s*(.*?)\s*```', response_text, re.DOTALL)
    if match:
        return json.loads(match.group(1))
    
    # Tenta encontrar qualquer objeto JSON
    match = re.search(r'\{.*\}', response_text, re.DOTALL)
    if match:
        return json.loads(match.group(0))
    
    raise ValueError("N√£o foi poss√≠vel extrair JSON da resposta do Gemini")
```

---

## 6. Limites e Custos

| M√©trica | Estimativa |
|---------|-----------|
| Tokens por quest√£o (gera√ß√£o) | ~200-300 tokens |
| Tokens por explica√ß√£o | ~300-500 tokens |
| Custo estimado por bateria de 10 quest√µes (Gemini Flash) | ~$0.001 |
| Rate limit recomendado por usu√°rio | 60 req/min |
| Cache de quest√µes | Reutilizar quest√µes j√° geradas para o mesmo t√≥pico/dificuldade |
